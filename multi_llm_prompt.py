#T5 and BART are used to generate summaries. Mistral, a stronger llm is then used to act as a judge and generate a better summary

# --- 1. Load Models ---

# Load BART 
bart_model_name = "facebook/bart-large-cnn"
bart_tokenizer = AutoTokenizer.from_pretrained(bart_model_name)
bart_model = AutoModelForSeq2SeqLM.from_pretrained(bart_model_name).to(device)

# Load T5 
t5_model_name = "t5-base"
t5_tokenizer = AutoTokenizer.from_pretrained(t5_model_name)
t5_model = AutoModelForSeq2SeqLM.from_pretrained(t5_model_name).to(device)

# Load Mistral (The Judge/Refiner)
mistral_model_name = "mistralai/Mistral-7B-Instruct-v0.1"
mistral_tokenizer = AutoTokenizer.from_pretrained(mistral_model_name)
mistral_model = AutoModelForCausalLM.from_pretrained(
    mistral_model_name,
    torch_dtype=torch.float16,
    device_map="auto" 
)

# --- 2. Define Generation Functions ---

def generate_bart(article):
    inputs = bart_tokenizer(
        article, 
        return_tensors="pt", 
        truncation=True, 
        max_length=1024
    ).to(device)
    
    summary_ids = bart_model.generate(
        **inputs, 
        max_length=200, 
        min_length=80, 
        num_beams=4, 
        early_stopping=True
    )
    return bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)

def generate_t5(article):
    # T5 specifically requires a prefix to know what task to perform
    input_text = "summarize: " + article
    inputs = t5_tokenizer(
        input_text, 
        return_tensors="pt", 
        truncation=True, 
        max_length=1024
    ).to(device)
    
    summary_ids = t5_model.generate(
        **inputs, 
        max_length=200, 
        min_length=80, 
        num_beams=4, 
        early_stopping=True
    )
    return t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)

#Mistral is used as a judge 
def refine_with_mistral(source_text, summary_bart, summary_t5):
    # Constructing a specific prompt for hallucination reduction
    prompt = f"""[INST] You are an expert editor tasked with creating a perfectly accurate summary. 
    
    Here is the Source Text:
    "{source_text}"

    Here are two draft summaries generated by other models:
    Draft 1: {summary_bart}
    Draft 2: {summary_t5}

    Your Goal: Create a final summary that combines the best parts of Draft 1 and Draft 2. 
    CRITICAL INSTRUCTION: You must verify every fact against the Source Text. If a detail in the drafts is not present in the Source Text (hallucination), REMOVE IT. 
    
    Output only the final refined summary. [/INST]
    """
    
    inputs = mistral_tokenizer(prompt, return_tensors="pt").to(mistral_model.device)
    
    # Generate response
    generated_ids = mistral_model.generate(
        **inputs, 
        max_new_tokens=250, 
        do_sample=True, 
        temperature=0.7
    )
    
    # Decode and strip the prompt from the output
    decoded = mistral_tokenizer.decode(generated_ids[0], skip_special_tokens=True)
    
    # Depending on model behavior, we might need to string split to get just the answer
    # Mistral usually outputs the whole prompt + answer, so we split by [/INST]
    if "[/INST]" in decoded:
        return decoded.split("[/INST]")[1].strip()
    return decoded

# --- 3. Main Loop ---

final_results = []

# Assuming 'dataset' is already loaded from previous cells
for item in tqdm(dataset, desc="Processing Summaries"):
    article = item["article"]
    
    # 1. Generate Drafts
    bart_summary = generate_bart(article)
    t5_summary = generate_t5(article)
    
    # 2. Refine with Mistral
    # We truncate the source text for Mistral input to ensure it fits in context window if necessary
    truncated_source = article[:2000] 
    final_summary = refine_with_mistral(truncated_source, bart_summary, t5_summary)
    
    final_results.append({
        "source": article,
        "bart_draft": bart_summary,
        "t5_draft": t5_summary,
        "mistral_refined": final_summary
    })

# --- 4. Output ---

print("\n--- Summary Comparison ---")
print(f"Source (Snippet): {final_results[0]['source'][:200]}...")
print(f"\nBART Draft: \n{final_results[0]['bart_draft']}")
print(f"\nT5 Draft: \n{final_results[0]['t5_draft']}")
print("-" * 50)
print(f"\nMistral Refined (Final): \n{final_results[0]['mistral_refined']}")